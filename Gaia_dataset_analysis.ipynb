{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAIA Dataset Analysis\n",
    "## Understanding the 165 GAIA validation examples\n",
    "\n",
    "**Objective:** Analyze GAIA patterns and build RAG vector store  \n",
    "**Output:** Tool priorities and FAISS index for agent development\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup and imports\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter, OrderedDict\n",
    "import random\n",
    "import re\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import os\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"üîç GAIA Dataset Analysis\")\n",
    "print(\"=\" * 40)\n",
    "print(\"Goal: Understand patterns and build vector store\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: Load & Explore GAIA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gaia_metadata(file_path='metadata.jsonl'):\n",
    "    \"\"\"Load and parse GAIA validation dataset\"\"\"\n",
    "    try:\n",
    "        json_QA = []\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                json_data = json.loads(line.strip())\n",
    "                json_QA.append(json_data)\n",
    "        \n",
    "        print(f\"‚úÖ Successfully loaded {len(json_QA)} GAIA examples\")\n",
    "        return json_QA\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå metadata.jsonl not found. Creating sample data for demonstration.\")\n",
    "        return create_sample_gaia_data()\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading GAIA data: {e}\")\n",
    "        return []\n",
    "\n",
    "def create_sample_gaia_data():\n",
    "    \"\"\"Create sample GAIA data for demonstration purposes\"\"\"\n",
    "    sample_data = [\n",
    "        {\n",
    "            'task_id': 'sample_001',\n",
    "            'Question': 'What is the population of Seattle according to the 2020 census?',\n",
    "            'Level': 1,\n",
    "            'Final answer': '737015',\n",
    "            'file_name': None,\n",
    "            'Annotator Metadata': {\n",
    "                'Steps': 'Search for Seattle population 2020 census data',\n",
    "                'Tools': 'web browser\\nsearch engine'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'task_id': 'sample_002', \n",
    "            'Question': 'Calculate the compound interest on $5000 at 3.5% annual rate for 10 years',\n",
    "            'Level': 2,\n",
    "            'Final answer': '7052.78',\n",
    "            'file_name': None,\n",
    "            'Annotator Metadata': {\n",
    "                'Steps': 'Use compound interest formula: A = P(1 + r)^t',\n",
    "                'Tools': 'calculator'\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            'task_id': 'sample_003',\n",
    "            'Question': 'What is the average temperature in the attached Excel file?',\n",
    "            'Level': 1,\n",
    "            'Final answer': '23.4',\n",
    "            'file_name': 'temperature_data.xlsx',\n",
    "            'Annotator Metadata': {\n",
    "                'Steps': 'Open Excel file, calculate average of temperature column',\n",
    "                'Tools': 'excel\\ncalculator'\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    print(\"üìù Using sample GAIA data for demonstration\")\n",
    "    return sample_data\n",
    "\n",
    "# Load the dataset\n",
    "json_QA = load_gaia_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic dataset statistics\n",
    "if json_QA:\n",
    "    print(f\"\\nüìà Dataset Overview:\")\n",
    "    print(f\"  ‚îú‚îÄ‚îÄ Total Questions: {len(json_QA)}\")\n",
    "    \n",
    "    # Level distribution\n",
    "    if 'Level' in json_QA[0]:\n",
    "        levels = [q.get('Level', 'Unknown') for q in json_QA]\n",
    "        level_counts = Counter(levels)\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ Level Distribution:\")\n",
    "        for level in sorted(level_counts.keys()):\n",
    "            print(f\"  ‚îÇ   ‚îú‚îÄ‚îÄ Level {level}: {level_counts[level]} questions\")\n",
    "    \n",
    "    # File attachment analysis\n",
    "    files_present = sum(1 for q in json_QA if q.get('file_name'))\n",
    "    print(f\"  ‚îú‚îÄ‚îÄ Questions with Files: {files_present}\")\n",
    "    print(f\"  ‚îî‚îÄ‚îÄ Questions without Files: {len(json_QA) - files_present}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_gaia_patterns(sample_size=5):\n",
    "    \"\"\"Analyze question patterns and structures\"\"\"\n",
    "    if not json_QA:\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüîç Sample Question Analysis (Random {sample_size}):\")\n",
    "    print(\"=\" * 120)\n",
    "    \n",
    "    sample_questions = random.sample(json_QA, min(sample_size, len(json_QA)))\n",
    "    \n",
    "    for i, sample in enumerate(sample_questions, 1):\n",
    "        print(f\"\\nüìù Question {i}:\")\n",
    "        print(f\"ID: {sample.get('task_id', 'N/A')}\")\n",
    "        print(f\"Level: {sample.get('Level', 'N/A')}\")\n",
    "        print(f\"Question: {sample.get('Question', 'N/A')[:100]}...\")\n",
    "        print(f\"File: {sample.get('file_name', 'None')}\")\n",
    "        \n",
    "        if 'Annotator Metadata' in sample:\n",
    "            metadata = sample['Annotator Metadata']\n",
    "            print(f\"Steps: {metadata.get('Steps', 'N/A')[:80]}...\")\n",
    "            print(f\"Tools: {metadata.get('Tools', 'N/A')}\")\n",
    "        \n",
    "        print(f\"Answer: {sample.get('Final answer', 'N/A')}\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "# Run pattern analysis\n",
    "analyze_gaia_patterns()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2: Tool Usage Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "def analyze_tool_usage_fixed():\n",
    "    \"\"\"Analyze tool frequency with proper normalization\"\"\"\n",
    "    if not json_QA:\n",
    "        return {}\n",
    "    \n",
    "    tools = []\n",
    "    tool_details = []\n",
    "    \n",
    "    def normalize_tool_name(tool):\n",
    "        \"\"\"Normalize tool names to remove duplicates\"\"\"\n",
    "        # Convert to lowercase\n",
    "        tool = tool.lower().strip()\n",
    "        \n",
    "        # Remove numbered prefixes (1., 2., 3., etc.)\n",
    "        tool = re.sub(r'^\\d+\\.\\s*', '', tool)\n",
    "        \n",
    "        # Remove articles (a, an, the)\n",
    "        tool = re.sub(r'^(a|an|the)\\s+', '', tool)\n",
    "        \n",
    "        # Remove parentheses and content inside\n",
    "        tool = re.sub(r'\\([^)]*\\)', '', tool)\n",
    "        \n",
    "        # Remove extra whitespace\n",
    "        tool = ' '.join(tool.split())\n",
    "        \n",
    "        # Common normalizations\n",
    "        normalizations = {\n",
    "            'web browser': ['browser', 'web browsers', 'internet browser'],\n",
    "            'search engine': ['search engines', 'google search', 'web search'],\n",
    "            'calculator': ['math calculator', 'calculations', 'calculation tool'],\n",
    "            'excel': ['microsoft excel', 'spreadsheet', 'ms excel'],\n",
    "            'pdf viewer': ['pdf reader', 'pdf access', 'pdf'],\n",
    "            'image recognition': ['image recognition tools', 'image analysis', 'image processing'],\n",
    "            'text editor': ['word processor', 'text processing'],\n",
    "            'file manager': ['file explorer', 'file system'],\n",
    "            'audio player': ['music player', 'media player'],\n",
    "            'video player': ['video viewer', 'media player']\n",
    "        }\n",
    "        \n",
    "        # Apply normalizations\n",
    "        for canonical, variants in normalizations.items():\n",
    "            if tool in variants or any(variant in tool for variant in variants):\n",
    "                return canonical\n",
    "        \n",
    "        return tool\n",
    "    \n",
    "    for sample in json_QA:\n",
    "        if 'Annotator Metadata' in sample and 'Tools' in sample['Annotator Metadata']:\n",
    "            tools_text = sample['Annotator Metadata']['Tools']\n",
    "            \n",
    "            # Parse tools (handle different formats)\n",
    "            tool_lines = tools_text.split('\\n')\n",
    "            for tool_line in tool_lines:\n",
    "                tool = tool_line.strip()\n",
    "                \n",
    "                # Skip empty lines\n",
    "                if not tool:\n",
    "                    continue\n",
    "                \n",
    "                # Remove bullet points and list markers\n",
    "                tool = re.sub(r'^[-‚Ä¢*]\\s*', '', tool)\n",
    "                \n",
    "                # Normalize the tool name\n",
    "                normalized_tool = normalize_tool_name(tool)\n",
    "                \n",
    "                if normalized_tool and normalized_tool != 'none':\n",
    "                    tools.append(normalized_tool)\n",
    "                    tool_details.append({\n",
    "                        'tool': normalized_tool,\n",
    "                        'original': tool,\n",
    "                        'question_id': sample.get('task_id'),\n",
    "                        'level': sample.get('Level'),\n",
    "                        'has_file': sample.get('file_name') is not None\n",
    "                    })\n",
    "    \n",
    "    # Count tool frequencies\n",
    "    tools_counter = OrderedDict(Counter(tools).most_common())\n",
    "    \n",
    "    print(\"üéØ Fixed Tool Usage Priority Analysis:\")\n",
    "    print(f\"Total tool instances: {len(tools)}\")\n",
    "    print(f\"Unique tools identified: {len(tools_counter)}\")\n",
    "    print(\"\\nüìä Implementation Priority (by frequency):\")\n",
    "    \n",
    "    for i, (tool, count) in enumerate(tools_counter.items(), 1):\n",
    "        if count >= 20:\n",
    "            priority = \"üî¥ CRITICAL\"\n",
    "        elif count >= 10:\n",
    "            priority = \"üü† HIGH\"\n",
    "        elif count >= 5:\n",
    "            priority = \"üü° MEDIUM\"\n",
    "        else:\n",
    "            priority = \"üü¢ LOW\"\n",
    "        \n",
    "        print(f\"  {i:2d}. {tool:<25} : {count:3d} occurrences {priority}\")\n",
    "        \n",
    "        if i <= 10:  # Show top 10 details\n",
    "            # Show which levels use this tool most\n",
    "            level_usage = {}\n",
    "            for detail in tool_details:\n",
    "                if detail['tool'] == tool:\n",
    "                    level = detail['level']\n",
    "                    level_usage[level] = level_usage.get(level, 0) + 1\n",
    "            \n",
    "            level_str = \", \".join([f\"L{k}:{v}\" for k, v in sorted(level_usage.items())])\n",
    "            print(f\"      ‚îî‚îÄ‚îÄ Level usage: {level_str}\")\n",
    "    \n",
    "    return tools_counter, tool_details\n",
    "\n",
    "def create_implementation_roadmap(tools_counter):\n",
    "    \"\"\"Create implementation roadmap based on tool frequency\"\"\"\n",
    "    \n",
    "    print(\"\\nüöÄ GAIA Agent Implementation Roadmap:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Group tools by implementation priority\n",
    "    critical_tools = []\n",
    "    high_tools = []\n",
    "    medium_tools = []\n",
    "    \n",
    "    for tool, count in tools_counter.items():\n",
    "        if count >= 20:\n",
    "            critical_tools.append((tool, count))\n",
    "        elif count >= 10:\n",
    "            high_tools.append((tool, count))\n",
    "        elif count >= 5:\n",
    "            medium_tools.append((tool, count))\n",
    "    \n",
    "    print(\"üî¥ PHASE 1 - CRITICAL (implement first):\")\n",
    "    for tool, count in critical_tools:\n",
    "        print(f\"  ‚úÖ {tool} ({count} uses)\")\n",
    "    \n",
    "    print(\"\\nüü† PHASE 2 - HIGH PRIORITY:\")\n",
    "    for tool, count in high_tools:\n",
    "        print(f\"  üîß {tool} ({count} uses)\")\n",
    "    \n",
    "    print(\"\\nüü° PHASE 3 - MEDIUM PRIORITY:\")\n",
    "    for tool, count in medium_tools:\n",
    "        print(f\"  ‚öôÔ∏è {tool} ({count} uses)\")\n",
    "    \n",
    "    # Map to actual tool implementations\n",
    "    print(\"\\nüõ†Ô∏è RECOMMENDED TOOL MAPPING:\")\n",
    "    tool_mapping = {\n",
    "        'web browser': 'ContentRetrieverTool + WebDriverTool',\n",
    "        'search engine': 'GoogleSearchTool + SerperTool', \n",
    "        'calculator': 'GAIACalculatorTool + PythonREPL',\n",
    "        'excel': 'GetAttachmentTool + PandasTool',\n",
    "        'pdf viewer': 'ContentRetrieverTool + PyPDFTool',\n",
    "        'image recognition': 'VisionTool + ImageAnalysisTool',\n",
    "        'text editor': 'TextProcessingTool',\n",
    "        'file manager': 'GetAttachmentTool + FileSystemTool'\n",
    "    }\n",
    "    \n",
    "    for tool, count in list(tools_counter.items())[:8]:\n",
    "        implementation = tool_mapping.get(tool, f\"Custom{tool.title().replace(' ', '')}Tool\")\n",
    "        print(f\"  {tool:<20} ‚Üí {implementation}\")\n",
    "\n",
    "# Run the fixed analysis\n",
    "tools_counter, tool_details = analyze_tool_usage_fixed()\n",
    "create_implementation_roadmap(tools_counter)\n",
    "\n",
    "# Show some examples of what was normalized\n",
    "print(\"\\nüîç Normalization Examples:\")\n",
    "unique_originals = {}\n",
    "for detail in tool_details[:20]:  # Show first 20\n",
    "    tool = detail['tool']\n",
    "    original = detail['original']\n",
    "    if tool not in unique_originals:\n",
    "        unique_originals[tool] = []\n",
    "    if original not in unique_originals[tool]:\n",
    "        unique_originals[tool].append(original)\n",
    "\n",
    "for tool, originals in list(unique_originals.items())[:5]:\n",
    "    if len(originals) > 1:\n",
    "        print(f\"  '{tool}' ‚Üê {originals}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of tool usage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "def create_tool_usage_visualization(tools_counter):\n",
    "    \"\"\"Create an enhanced visualization of tool usage with updated priority levels\"\"\"\n",
    "    \n",
    "    if not tools_counter:\n",
    "        print(\"‚ùå No tools data to visualize\")\n",
    "        return\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 10))\n",
    "    \n",
    "    # ===== MAIN BAR CHART =====\n",
    "    # Top 15 tools\n",
    "    top_tools = list(tools_counter.items())[:15]\n",
    "    tool_names = [item[0] for item in top_tools]\n",
    "    tool_counts = [item[1] for item in top_tools]\n",
    "    \n",
    "    # Updated color scheme with new thresholds\n",
    "    colors = []\n",
    "    for count in tool_counts:\n",
    "        if count >= 20:\n",
    "            colors.append('#DC2626')  # Red - CRITICAL\n",
    "        elif count >= 10:\n",
    "            colors.append('#F59E0B')  # Orange - HIGH\n",
    "        elif count >= 5:\n",
    "            colors.append('#10B981')  # Green - MEDIUM\n",
    "        else:\n",
    "            colors.append('#6B7280')  # Gray - LOW\n",
    "    \n",
    "    bars = ax1.barh(range(len(tool_names)), tool_counts, color=colors, alpha=0.8)\n",
    "    ax1.set_yticks(range(len(tool_names)))\n",
    "    ax1.set_yticklabels(tool_names, fontsize=10)\n",
    "    ax1.set_xlabel('Usage Frequency', fontsize=12, fontweight='bold')\n",
    "    ax1.set_title('GAIA Tool Usage Analysis\\n(Normalized & Cleaned)', fontsize=14, fontweight='bold')\n",
    "    ax1.invert_yaxis()\n",
    "    \n",
    "    # Add count labels on bars\n",
    "    for i, (bar, count) in enumerate(zip(bars, tool_counts)):\n",
    "        # Position label inside bar if bar is wide enough, otherwise outside\n",
    "        label_x = bar.get_width() - 2 if bar.get_width() > 10 else bar.get_width() + 0.5\n",
    "        label_color = 'white' if bar.get_width() > 10 else 'black'\n",
    "        \n",
    "        ax1.text(label_x, bar.get_y() + bar.get_height()/2, \n",
    "                str(count), va='center', ha='right' if bar.get_width() > 10 else 'left',\n",
    "                fontweight='bold', color=label_color, fontsize=9)\n",
    "    \n",
    "    # Add priority zone backgrounds\n",
    "    ax1.axvspan(20, max(tool_counts) + 5, alpha=0.1, color='red', label='Critical Zone')\n",
    "    ax1.axvspan(10, 20, alpha=0.1, color='orange', label='High Zone')\n",
    "    ax1.axvspan(5, 10, alpha=0.1, color='green', label='Medium Zone')\n",
    "    \n",
    "    # Enhanced legend\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='#DC2626', label='üî¥ CRITICAL (‚â•20 uses)'),\n",
    "        Patch(facecolor='#F59E0B', label='üü† HIGH (10-19 uses)'),\n",
    "        Patch(facecolor='#10B981', label='üü° MEDIUM (5-9 uses)'),\n",
    "        Patch(facecolor='#6B7280', label='üü¢ LOW (<5 uses)')\n",
    "    ]\n",
    "    ax1.legend(handles=legend_elements, loc='lower right', fontsize=10)\n",
    "    \n",
    "    # ===== IMPLEMENTATION PRIORITY PIE CHART =====\n",
    "    # Calculate priority distribution\n",
    "    critical_count = sum(1 for count in tools_counter.values() if count >= 20)\n",
    "    high_count = sum(1 for count in tools_counter.values() if 10 <= count < 20)\n",
    "    medium_count = sum(1 for count in tools_counter.values() if 5 <= count < 10)\n",
    "    low_count = sum(1 for count in tools_counter.values() if count < 5)\n",
    "    \n",
    "    priority_labels = ['CRITICAL', 'HIGH', 'MEDIUM', 'LOW']\n",
    "    priority_counts = [critical_count, high_count, medium_count, low_count]\n",
    "    priority_colors = ['#DC2626', '#F59E0B', '#10B981', '#6B7280']\n",
    "    \n",
    "    # Only show non-zero segments\n",
    "    non_zero_data = [(label, count, color) for label, count, color in \n",
    "                     zip(priority_labels, priority_counts, priority_colors) if count > 0]\n",
    "    \n",
    "    if non_zero_data:\n",
    "        labels, counts, colors = zip(*non_zero_data)\n",
    "        \n",
    "        wedges, texts, autotexts = ax2.pie(counts, labels=labels, colors=colors, autopct='%1.0f%%',\n",
    "                                          startangle=90, textprops={'fontsize': 10})\n",
    "        \n",
    "        # Enhance pie chart text\n",
    "        for autotext in autotexts:\n",
    "            autotext.set_color('white')\n",
    "            autotext.set_fontweight('bold')\n",
    "        \n",
    "        ax2.set_title('Implementation Priority Distribution\\n(Tool Count by Priority)', \n",
    "                     fontsize=12, fontweight='bold')\n",
    "        \n",
    "        # Add total count in center\n",
    "        total_tools = len(tools_counter)\n",
    "        ax2.text(0, 0, f'{total_tools}\\nTotal\\nTools', ha='center', va='center',\n",
    "                fontsize=14, fontweight='bold', \n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # ===== SUMMARY STATS =====\n",
    "    print(\"\\nüìä VISUALIZATION SUMMARY:\")\n",
    "    print(\"=\" * 40)\n",
    "    print(f\"Total unique tools: {len(tools_counter)}\")\n",
    "    print(f\"Total tool instances: {sum(tools_counter.values())}\")\n",
    "    print(f\"üî¥ Critical tools (‚â•20): {critical_count}\")\n",
    "    print(f\"üü† High priority (10-19): {high_count}\")\n",
    "    print(f\"üü° Medium priority (5-9): {medium_count}\")\n",
    "    print(f\"üü¢ Low priority (<5): {low_count}\")\n",
    "    \n",
    "    # Show top 5 with percentages\n",
    "    total_instances = sum(tools_counter.values())\n",
    "    print(f\"\\nüéØ TOP 5 TOOLS (% of total usage):\")\n",
    "    for i, (tool, count) in enumerate(list(tools_counter.items())[:5], 1):\n",
    "        percentage = (count / total_instances) * 100\n",
    "        print(f\"  {i}. {tool:<20}: {count:3d} uses ({percentage:5.1f}%)\")\n",
    "\n",
    "def create_level_breakdown_chart(tool_details):\n",
    "    \"\"\"Additional chart showing tool usage by GAIA level\"\"\"\n",
    "    \n",
    "    if not tool_details:\n",
    "        return\n",
    "    \n",
    "    # Analyze tool usage by level\n",
    "    level_tool_usage = {}\n",
    "    for detail in tool_details:\n",
    "        level = detail.get('level', 'Unknown')\n",
    "        tool = detail['tool']\n",
    "        \n",
    "        if level not in level_tool_usage:\n",
    "            level_tool_usage[level] = {}\n",
    "        \n",
    "        level_tool_usage[level][tool] = level_tool_usage[level].get(tool, 0) + 1\n",
    "    \n",
    "    # Create stacked bar chart\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    \n",
    "    # Get top 10 tools\n",
    "    from collections import Counter\n",
    "    all_tools = [detail['tool'] for detail in tool_details]\n",
    "    top_10_tools = [tool for tool, _ in Counter(all_tools).most_common(10)]\n",
    "    \n",
    "    # Prepare data for stacked bars\n",
    "    levels = sorted(level_tool_usage.keys())\n",
    "    level_data = {level: [] for level in levels}\n",
    "    \n",
    "    for tool in top_10_tools:\n",
    "        for level in levels:\n",
    "            count = level_tool_usage[level].get(tool, 0)\n",
    "            level_data[level].append(count)\n",
    "    \n",
    "    # Create stacked bars\n",
    "    bottom = np.zeros(len(top_10_tools))\n",
    "    colors_level = ['#EF4444', '#F59E0B', '#10B981']  # Red, Orange, Green for levels 1,2,3\n",
    "    \n",
    "    for i, level in enumerate(levels):\n",
    "        plt.bar(top_10_tools, level_data[level], bottom=bottom, \n",
    "               label=f'Level {level}', color=colors_level[i % len(colors_level)], alpha=0.8)\n",
    "        bottom += level_data[level]\n",
    "    \n",
    "    plt.xlabel('Tools', fontsize=12, fontweight='bold')\n",
    "    plt.ylabel('Usage Count', fontsize=12, fontweight='bold')\n",
    "    plt.title('Tool Usage by GAIA Difficulty Level\\n(Top 10 Tools)', fontsize=14, fontweight='bold')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.legend(title='GAIA Level', fontsize=10)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage after running the fixed analysis:\n",
    "if 'tools_counter' in globals() and tools_counter:\n",
    "    print(\"üé® Creating enhanced visualizations...\")\n",
    "    create_tool_usage_visualization(tools_counter)\n",
    "    \n",
    "    if 'tool_details' in globals() and tool_details:\n",
    "        create_level_breakdown_chart(tool_details)\n",
    "else:\n",
    "    print(\"‚ùå Run the fixed tool analysis first to generate visualizations\")\n",
    "    print(\"Execute: tools_counter, tool_details = analyze_tool_usage_fixed()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_implementation_recommendations(tools_counter):\n",
    "    \"\"\"Generate data-driven tool implementation recommendations\"\"\"\n",
    "    if not tools_counter:\n",
    "        return\n",
    "    \n",
    "    print(\"\\nüí° Implementation Recommendations:\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    # Essential tools (high frequency)\n",
    "    essential = [(tool, count) for tool, count in tools_counter.items() if count >= 10]\n",
    "    important = [(tool, count) for tool, count in tools_counter.items() if 5 <= count < 10]\n",
    "    optional = [(tool, count) for tool, count in tools_counter.items() if count < 5]\n",
    "    \n",
    "    print(f\"üî¥ ESSENTIAL TOOLS (Implement First):\")\n",
    "    for tool, count in essential:\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ {tool}: {count} occurrences\")\n",
    "    \n",
    "    print(f\"\\nüü° IMPORTANT TOOLS (Implement Second):\")\n",
    "    for tool, count in important:\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ {tool}: {count} occurrences\")\n",
    "    \n",
    "    print(f\"\\nüü¢ OPTIONAL TOOLS (If Budget Allows):\")\n",
    "    for tool, count in optional[:5]:  # Show top 5 optional\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ {tool}: {count} occurrences\")\n",
    "    \n",
    "    # File type analysis\n",
    "    print(f\"\\nüìÅ File Processing Requirements:\")\n",
    "    file_questions = [q for q in json_QA if q.get('file_name')]\n",
    "    if file_questions:\n",
    "        file_extensions = []\n",
    "        for q in file_questions:\n",
    "            filename = q.get('file_name', '')\n",
    "            if '.' in filename:\n",
    "                ext = Path(filename).suffix.lower()\n",
    "                file_extensions.append(ext)\n",
    "        \n",
    "        ext_counts = Counter(file_extensions)\n",
    "        for ext, count in ext_counts.most_common():\n",
    "            print(f\"  ‚îú‚îÄ‚îÄ {ext}: {count} files\")\n",
    "\n",
    "# Generate recommendations\n",
    "generate_implementation_recommendations(tools_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3: Build Weaviate Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAIA Weaviate Vector Store - LangChain Implementation with Efficient Serialization\n",
    "# Uses LangChain's serialize_to_bytes() to avoid model bloat\n",
    "\n",
    "# Weaviate GAIA Vector Store Implementation\n",
    "# Modern, numpy 2.0 compatible, production-ready\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import weaviate\n",
    "import weaviate.classes as wvc\n",
    "from weaviate.classes.config import Property, DataType\n",
    "\n",
    "# Configuration\n",
    "WEAVIATE_URL = \"http://localhost:8080\"  # Local Docker\n",
    "COLLECTION_NAME = \"GAIAExamples\"\n",
    "EMBEDDING_MODEL = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "\n",
    "def check_weaviate_dependencies():\n",
    "    \"\"\"Check if Weaviate dependencies are available\"\"\"\n",
    "    missing = []\n",
    "    \n",
    "    try:\n",
    "        import weaviate\n",
    "        print(\"‚úÖ Weaviate client available\")\n",
    "    except ImportError:\n",
    "        missing.append(\"weaviate-client\")\n",
    "        print(\"‚ùå Weaviate client not available\")\n",
    "    \n",
    "    try:\n",
    "        from langchain_weaviate import WeaviateVectorStore\n",
    "        print(\"‚úÖ LangChain Weaviate available\")\n",
    "    except ImportError:\n",
    "        missing.append(\"langchain-weaviate\")\n",
    "        print(\"‚ùå LangChain Weaviate not available\")\n",
    "    \n",
    "    try:\n",
    "        from langchain_huggingface import HuggingFaceEmbeddings\n",
    "        print(\"‚úÖ HuggingFace embeddings available\")\n",
    "    except ImportError:\n",
    "        missing.append(\"langchain-huggingface\")\n",
    "        print(\"‚ùå HuggingFace embeddings not available\")\n",
    "    \n",
    "    if missing:\n",
    "        print(f\"\\nüì¶ Missing packages: {missing}\")\n",
    "        print(\"Install with:\")\n",
    "        for pkg in missing:\n",
    "            print(f\"  poetry add {pkg}\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "def setup_local_weaviate():\n",
    "    \"\"\"Setup local Weaviate with Docker Compose\"\"\"\n",
    "    docker_compose = \"\"\"\n",
    "version: '3.4'\n",
    "services:\n",
    "  weaviate:\n",
    "    command:\n",
    "    - --host\n",
    "    - 0.0.0.0\n",
    "    - --port\n",
    "    - '8080'\n",
    "    - --scheme\n",
    "    - http\n",
    "    image: cr.weaviate.io/semitechnologies/weaviate:1.26.1\n",
    "    ports:\n",
    "    - 8080:8080\n",
    "    - 50051:50051\n",
    "    restart: on-failure:0\n",
    "    environment:\n",
    "      QUERY_DEFAULTS_LIMIT: 25\n",
    "      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'\n",
    "      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'\n",
    "      DEFAULT_VECTORIZER_MODULE: 'text2vec-huggingface'\n",
    "      ENABLE_MODULES: 'text2vec-huggingface'\n",
    "      HUGGINGFACE_APIKEY: 'YOUR_HUGGINGFACE_KEY'  # Optional for local models\n",
    "      CLUSTER_HOSTNAME: 'node1'\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"üê≥ Docker Compose for Weaviate:\")\n",
    "    print(\"Save this as docker-compose.yml and run: docker-compose up -d\")\n",
    "    print(docker_compose)\n",
    "\n",
    "def connect_to_weaviate(url: str = WEAVIATE_URL) -> weaviate.WeaviateClient:\n",
    "    \"\"\"Connect to Weaviate instance\"\"\"\n",
    "    try:\n",
    "        # Try connecting to local instance\n",
    "        client = weaviate.connect_to_local(\n",
    "            host=\"localhost\",\n",
    "            port=8080,\n",
    "            grpc_port=50051\n",
    "        )\n",
    "        \n",
    "        if client.is_ready():\n",
    "            print(f\"‚úÖ Connected to Weaviate at {url}\")\n",
    "            return client\n",
    "        else:\n",
    "            print(f\"‚ùå Weaviate not ready at {url}\")\n",
    "            return None\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to connect to Weaviate: {e}\")\n",
    "        print(\"üí° Make sure Weaviate is running with Docker:\")\n",
    "        print(\"   docker-compose up -d\")\n",
    "        return None\n",
    "\n",
    "def create_gaia_collection(client: weaviate.WeaviateClient) -> bool:\n",
    "    \"\"\"Create GAIA collection in Weaviate\"\"\"\n",
    "    try:\n",
    "        # Delete existing collection if it exists\n",
    "        if client.collections.exists(COLLECTION_NAME):\n",
    "            print(f\"üóëÔ∏è Deleting existing collection: {COLLECTION_NAME}\")\n",
    "            client.collections.delete(COLLECTION_NAME)\n",
    "        \n",
    "        # Create new collection with schema\n",
    "        collection = client.collections.create(\n",
    "            name=COLLECTION_NAME,\n",
    "            properties=[\n",
    "                Property(name=\"task_id\", data_type=DataType.TEXT),\n",
    "                Property(name=\"question\", data_type=DataType.TEXT),\n",
    "                Property(name=\"answer\", data_type=DataType.TEXT),\n",
    "                Property(name=\"level\", data_type=DataType.INT),\n",
    "                Property(name=\"has_file\", data_type=DataType.BOOL),\n",
    "                Property(name=\"steps\", data_type=DataType.TEXT),\n",
    "                Property(name=\"content\", data_type=DataType.TEXT),  # Main searchable content\n",
    "            ],\n",
    "            # Use built-in text2vec-huggingface vectorizer\n",
    "            vectorizer_config=wvc.config.Configure.Vectorizer.text2vec_huggingface(\n",
    "                model=EMBEDDING_MODEL\n",
    "            ),\n",
    "            # Configure which field to vectorize\n",
    "            vector_index_config=wvc.config.Configure.VectorIndex.hnsw(),\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Created collection: {COLLECTION_NAME}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to create collection: {e}\")\n",
    "        return False\n",
    "\n",
    "def populate_gaia_collection(client: weaviate.WeaviateClient, json_QA: List[Dict], max_examples: Optional[int] = None) -> bool:\n",
    "    \"\"\"Populate Weaviate collection with GAIA examples\"\"\"\n",
    "    try:\n",
    "        collection = client.collections.get(COLLECTION_NAME)\n",
    "        \n",
    "        # Limit examples if specified\n",
    "        examples = json_QA[:max_examples] if max_examples else json_QA\n",
    "        print(f\"üìö Populating collection with {len(examples)} examples...\")\n",
    "        \n",
    "        # Prepare data objects for batch insert\n",
    "        data_objects = []\n",
    "        \n",
    "        for i, sample in enumerate(examples):\n",
    "            # Create rich content for vectorization\n",
    "            content = f\"Question: {sample.get('Question', '')}\"\n",
    "            \n",
    "            if sample.get('Final answer'):\n",
    "                content += f\"\\nAnswer: {sample.get('Final answer', '')}\"\n",
    "            \n",
    "            # Add steps if available\n",
    "            steps = \"\"\n",
    "            if (sample.get('Annotator Metadata') and \n",
    "                sample['Annotator Metadata'].get('Steps')):\n",
    "                steps = sample['Annotator Metadata']['Steps']\n",
    "                content += f\"\\nSteps: {steps}\"\n",
    "            \n",
    "            # Create data object\n",
    "            data_obj = {\n",
    "                \"task_id\": sample.get('task_id', f'gaia_{i}'),\n",
    "                \"question\": sample.get('Question', ''),\n",
    "                \"answer\": sample.get('Final answer', ''),\n",
    "                \"level\": sample.get('Level', 1),\n",
    "                \"has_file\": sample.get('file_name') is not None,\n",
    "                \"steps\": steps,\n",
    "                \"content\": content,  # This gets vectorized\n",
    "            }\n",
    "            \n",
    "            data_objects.append(data_obj)\n",
    "        \n",
    "        print(f\"  ‚îú‚îÄ‚îÄ Average content length: {sum(len(obj['content']) for obj in data_objects) / len(data_objects):.0f} chars\")\n",
    "        \n",
    "        # Batch insert with automatic vectorization\n",
    "        print(\"üîÑ Inserting data with automatic vectorization...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Use batch insert for efficiency\n",
    "        with collection.batch.dynamic() as batch:\n",
    "            for obj in data_objects:\n",
    "                batch.add_object(obj)\n",
    "        \n",
    "        duration = time.time() - start_time\n",
    "        \n",
    "        # Verify insertion\n",
    "        total_objects = collection.aggregate.over_all(total_count=True).total_count\n",
    "        \n",
    "        print(f\"‚úÖ Successfully inserted {total_objects} objects in {duration:.2f} seconds\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ Rate: {total_objects/duration:.1f} objects/second\")\n",
    "        print(f\"  ‚îî‚îÄ‚îÄ Collection: {COLLECTION_NAME}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to populate collection: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "\n",
    "def search_gaia_examples(client: weaviate.WeaviateClient, query: str, k: int = 3) -> List[Tuple[Dict, float]]:\n",
    "    \"\"\"Search for similar GAIA examples\"\"\"\n",
    "    try:\n",
    "        collection = client.collections.get(COLLECTION_NAME)\n",
    "        \n",
    "        # Perform semantic search\n",
    "        response = collection.query.near_text(\n",
    "            query=query,\n",
    "            limit=k,\n",
    "            return_metadata=wvc.query.MetadataQuery(distance=True, certainty=True)\n",
    "        )\n",
    "        \n",
    "        # Format results\n",
    "        results = []\n",
    "        for obj in response.objects:\n",
    "            # Extract properties\n",
    "            meta = {\n",
    "                'task_id': obj.properties.get('task_id'),\n",
    "                'question': obj.properties.get('question'),\n",
    "                'answer': obj.properties.get('answer'),\n",
    "                'level': obj.properties.get('level'),\n",
    "                'has_file': obj.properties.get('has_file'),\n",
    "                'steps': obj.properties.get('steps'),\n",
    "            }\n",
    "            \n",
    "            # Convert distance to similarity score (higher = more similar)\n",
    "            distance = obj.metadata.distance or 0\n",
    "            similarity_score = 1 - distance  # Convert distance to similarity\n",
    "            \n",
    "            results.append((meta, similarity_score))\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Search failed: {e}\")\n",
    "        return []\n",
    "\n",
    "def print_search_results(query: str, results: List[Tuple[Dict, float]]):\n",
    "    \"\"\"Pretty print search results\"\"\"\n",
    "    print(f\"\\nüîç Query: '{query}'\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"‚ùå No results found\")\n",
    "        return\n",
    "    \n",
    "    for i, (meta, score) in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. Similarity: {score:.3f} | Level: {meta.get('level', 'N/A')}\")\n",
    "        print(f\"   Question: {meta.get('question', '')[:100]}...\")\n",
    "        print(f\"   Answer: {meta.get('answer', '')[:100]}...\")\n",
    "        if meta.get('has_file'):\n",
    "            print(f\"   üìé Has attachment\")\n",
    "\n",
    "def get_collection_info(client: weaviate.WeaviateClient):\n",
    "    \"\"\"Get information about the GAIA collection\"\"\"\n",
    "    try:\n",
    "        if not client.collections.exists(COLLECTION_NAME):\n",
    "            print(f\"‚ùå Collection {COLLECTION_NAME} does not exist\")\n",
    "            return\n",
    "        \n",
    "        collection = client.collections.get(COLLECTION_NAME)\n",
    "        \n",
    "        # Get collection statistics\n",
    "        agg_result = collection.aggregate.over_all(\n",
    "            total_count=True,\n",
    "            group_by=\"level\"\n",
    "        )\n",
    "        \n",
    "        total_count = agg_result.total_count\n",
    "        \n",
    "        print(f\"üìä Collection Info: {COLLECTION_NAME}\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ Total objects: {total_count}\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ Vectorizer: text2vec-huggingface\")\n",
    "        print(f\"  ‚îú‚îÄ‚îÄ Model: {EMBEDDING_MODEL}\")\n",
    "        \n",
    "        # Level distribution\n",
    "        level_counts = {}\n",
    "        for group in agg_result.groups:\n",
    "            level = group.grouped_by.value\n",
    "            count = group.total_count\n",
    "            level_counts[level] = count\n",
    "        \n",
    "        print(f\"  ‚îî‚îÄ‚îÄ Level distribution: {level_counts}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error getting collection info: {e}\")\n",
    "\n",
    "# LANGCHAIN INTEGRATION\n",
    "\n",
    "def create_langchain_weaviate_store(client: weaviate.WeaviateClient):\n",
    "    \"\"\"Create LangChain Weaviate vector store\"\"\"\n",
    "    try:\n",
    "        from langchain_weaviate import WeaviateVectorStore\n",
    "        from langchain_huggingface import HuggingFaceEmbeddings\n",
    "        \n",
    "        # Create embeddings model (for LangChain compatibility)\n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=EMBEDDING_MODEL,\n",
    "            model_kwargs={'device': 'cpu'},\n",
    "            encode_kwargs={'batch_size': 8}\n",
    "        )\n",
    "        \n",
    "        # Create LangChain vector store\n",
    "        vectorstore = WeaviateVectorStore(\n",
    "            client=client,\n",
    "            index_name=COLLECTION_NAME,\n",
    "            text_key=\"content\",\n",
    "            embedding=embeddings,\n",
    "            attributes=[\"task_id\", \"question\", \"answer\", \"level\", \"has_file\", \"steps\"]\n",
    "        )\n",
    "        \n",
    "        print(\"‚úÖ LangChain Weaviate store created\")\n",
    "        return vectorstore\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to create LangChain store: {e}\")\n",
    "        return None\n",
    "\n",
    "def langchain_search_examples(vectorstore, query: str, k: int = 3) -> List[Dict]:\n",
    "    \"\"\"Search using LangChain interface\"\"\"\n",
    "    try:\n",
    "        # Search with scores\n",
    "        results = vectorstore.similarity_search_with_score(query, k=k)\n",
    "        \n",
    "        formatted_results = []\n",
    "        for doc, score in results:\n",
    "            meta = doc.metadata.copy()\n",
    "            meta['content'] = doc.page_content\n",
    "            meta['similarity_score'] = float(score)\n",
    "            formatted_results.append(meta)\n",
    "        \n",
    "        return formatted_results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå LangChain search failed: {e}\")\n",
    "        return []\n",
    "\n",
    "# PRODUCTION FUNCTIONS FOR GAIA AGENT\n",
    "\n",
    "class GAIAWeaviateStore:\n",
    "    \"\"\"Production-ready Weaviate store for GAIA agent\"\"\"\n",
    "    \n",
    "    def __init__(self, weaviate_url: str = WEAVIATE_URL):\n",
    "        self.client = None\n",
    "        self.vectorstore = None\n",
    "        self.url = weaviate_url\n",
    "        self._connect()\n",
    "    \n",
    "    def _connect(self):\n",
    "        \"\"\"Connect to Weaviate and setup vector store\"\"\"\n",
    "        self.client = connect_to_weaviate(self.url)\n",
    "        if self.client and self.client.collections.exists(COLLECTION_NAME):\n",
    "            self.vectorstore = create_langchain_weaviate_store(self.client)\n",
    "    \n",
    "    def is_ready(self) -> bool:\n",
    "        \"\"\"Check if the store is ready for use\"\"\"\n",
    "        return self.client is not None and self.vectorstore is not None\n",
    "    \n",
    "    def get_relevant_examples(self, question: str, k: int = 3, min_score: float = 0.7) -> List[Dict]:\n",
    "        \"\"\"Get relevant GAIA examples for a question\"\"\"\n",
    "        if not self.is_ready():\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            results = langchain_search_examples(self.vectorstore, question, k=k)\n",
    "            # Filter by minimum similarity score\n",
    "            return [r for r in results if r.get('similarity_score', 0) >= min_score]\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error getting examples: {e}\")\n",
    "            return []\n",
    "    \n",
    "    def format_for_prompt(self, examples: List[Dict], max_examples: int = 3) -> str:\n",
    "        \"\"\"Format examples for LLM prompt\"\"\"\n",
    "        if not examples:\n",
    "            return \"No relevant GAIA examples found.\"\n",
    "        \n",
    "        limited = examples[:max_examples]\n",
    "        \n",
    "        prompt_section = \"üìö Relevant GAIA Examples:\\n\\n\"\n",
    "        for i, ex in enumerate(limited, 1):\n",
    "            prompt_section += f\"Example {i} (Level {ex.get('level', 'N/A')}):\\n\"\n",
    "            prompt_section += f\"Q: {ex.get('question', '')}\\n\"\n",
    "            prompt_section += f\"A: {ex.get('answer', '')}\\n\"\n",
    "            \n",
    "            if ex.get('has_file'):\n",
    "                prompt_section += \"üìé Involves file processing\\n\"\n",
    "            \n",
    "            prompt_section += \"\\n\"\n",
    "        \n",
    "        return prompt_section\n",
    "    \n",
    "    def select_agent_with_context(self, question: str) -> Tuple[str, str]:\n",
    "        \"\"\"Select agent based on similar GAIA examples\"\"\"\n",
    "        examples = self.get_relevant_examples(question, k=2, min_score=0.6)\n",
    "        context = self.format_for_prompt(examples, max_examples=2)\n",
    "        \n",
    "        # Simple agent selection based on examples\n",
    "        if any(ex.get('has_file', False) for ex in examples):\n",
    "            return \"document_processor\", context\n",
    "        elif any('calculat' in ex.get('question', '').lower() for ex in examples):\n",
    "            return \"data_analyst\", context\n",
    "        elif any('search' in ex.get('question', '').lower() for ex in examples):\n",
    "            return \"web_researcher\", context\n",
    "        else:\n",
    "            return \"general_assistant\", context\n",
    "\n",
    "# SETUP AND TESTING FUNCTIONS\n",
    "\n",
    "def complete_weaviate_setup(json_QA: List[Dict], max_examples: Optional[int] = None) -> GAIAWeaviateStore:\n",
    "    \"\"\"Complete Weaviate setup for GAIA project\"\"\"\n",
    "    print(\"üöÄ Complete Weaviate Setup for GAIA\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check dependencies\n",
    "    if not check_weaviate_dependencies():\n",
    "        return None\n",
    "    \n",
    "    # Connect to Weaviate\n",
    "    client = connect_to_weaviate()\n",
    "    if not client:\n",
    "        print(\"üí° To start Weaviate locally:\")\n",
    "        setup_local_weaviate()\n",
    "        return None\n",
    "    \n",
    "    # Create collection\n",
    "    if not create_gaia_collection(client):\n",
    "        return None\n",
    "    \n",
    "    # Populate with data\n",
    "    if not populate_gaia_collection(client, json_QA, max_examples):\n",
    "        return None\n",
    "    \n",
    "    # Get collection info\n",
    "    get_collection_info(client)\n",
    "    \n",
    "    # Test search\n",
    "    print(\"\\nüß™ Testing search functionality...\")\n",
    "    results = search_gaia_examples(client, \"calculate compound interest\", k=3)\n",
    "    print_search_results(\"calculate compound interest\", results)\n",
    "    \n",
    "    # Create production store\n",
    "    store = GAIAWeaviateStore()\n",
    "    if store.is_ready():\n",
    "        print(\"\\n‚úÖ GAIA Weaviate store ready for production!\")\n",
    "        return store\n",
    "    else:\n",
    "        print(\"\\n‚ùå Failed to create production store\")\n",
    "        return None\n",
    "\n",
    "# Example usage for your GAIA project:\n",
    "\"\"\"\n",
    "# Setup Weaviate for GAIA\n",
    "store = complete_weaviate_setup(json_QA, max_examples=100)\n",
    "\n",
    "if store:\n",
    "    # Use in your agent\n",
    "    question = \"How do I calculate compound interest?\"\n",
    "    agent, context = store.select_agent_with_context(question)\n",
    "    print(f\"Selected agent: {agent}\")\n",
    "    print(f\"Context: {context}\")\n",
    "\"\"\"\n",
    "\n",
    "deps_available = check_weaviate_dependencies()\n",
    "print(f\"‚úÖ All dependencies available: {deps_available}\")\n",
    "\n",
    "if not deps_available:\n",
    "    print(\"\\nüì¶ Install missing packages with:\")\n",
    "    print(\"poetry add weaviate-client langchain-weaviate langchain-huggingface\")\n",
    "\n",
    "# Check numpy version\n",
    "import numpy as np\n",
    "print(f\"üìä NumPy version: {np.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start Weaviate (Docker Setup)\n",
    "# Run this to start Weaviate locally\n",
    "\n",
    "# Check if Weaviate is running\n",
    "client_test = connect_to_weaviate()\n",
    "\n",
    "if client_test is None:\n",
    "    print(\"üê≥ Weaviate not running. Setup Docker Compose:\")\n",
    "    setup_local_weaviate()\n",
    "    print(\"\\nüí° Steps to start Weaviate:\")\n",
    "    print(\"1. Save the docker-compose.yml content above to a file\")\n",
    "    print(\"2. Run: docker-compose up -d\")\n",
    "    print(\"3. Wait ~30 seconds for startup\")\n",
    "    print(\"4. Re-run this cell to verify connection\")\n",
    "else:\n",
    "    print(\"‚úÖ Weaviate is running and ready!\")\n",
    "    client_test.close()  # Close test connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load GAIA Data\n",
    "# Make sure your GAIA data is loaded\n",
    "\n",
    "# Check if json_QA is available from previous work\n",
    "if 'json_QA' in globals() and json_QA:\n",
    "    print(f\"‚úÖ GAIA data already loaded: {len(json_QA)} examples\")\n",
    "else:\n",
    "    # Load GAIA data (adjust path as needed)\n",
    "    json_QA = []\n",
    "    \n",
    "    # Option 1: From metadata.jsonl\n",
    "    if os.path.exists(\"metadata.jsonl\"):\n",
    "        print(\"üìÅ Loading from metadata.jsonl\")\n",
    "        with open(\"metadata.jsonl\", \"r\") as f:\n",
    "            for line in f:\n",
    "                item = json.loads(line.strip())\n",
    "                if item.get(\"Final answer\"):  # Only validation examples\n",
    "                    json_QA.append(item)\n",
    "    \n",
    "    # Option 2: From metadata.json\n",
    "    elif os.path.exists(\"metadata.json\"):\n",
    "        print(\"üìÅ Loading from metadata.json\")\n",
    "        with open(\"metadata.json\", \"r\") as f:\n",
    "            gaia_data = json.load(f)\n",
    "            json_QA = gaia_data.get(\"validation\", [])\n",
    "    \n",
    "    # Option 3: Load your existing data\n",
    "    # json_QA = your_existing_gaia_data\n",
    "    \n",
    "    print(f\"üìä Loaded {len(json_QA)} GAIA examples\")\n",
    "\n",
    "if json_QA:\n",
    "    sample = json_QA[0]\n",
    "    print(f\"Sample keys: {list(sample.keys())}\")\n",
    "    print(f\"Sample question: {sample.get('Question', '')[:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Complete Weaviate Setup (Main Setup)\n",
    "# This will create collection, populate data, and test\n",
    "\n",
    "if json_QA and deps_available:\n",
    "    print(\"üöÄ Starting complete Weaviate setup...\")\n",
    "    \n",
    "    # For testing, start with fewer examples (increase as needed)\n",
    "    max_examples = 100  # Adjust this number based on your needs\n",
    "    \n",
    "    # Run complete setup\n",
    "    store = complete_weaviate_setup(json_QA, max_examples=max_examples)\n",
    "    \n",
    "    if store:\n",
    "        print(\"\\nüéâ Weaviate setup successful!\")\n",
    "        print(\"‚úÖ Ready for GAIA agent integration\")\n",
    "    else:\n",
    "        print(\"\\nüí• Setup failed - check error messages above\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Cannot proceed: missing GAIA data or dependencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Test Basic Search Functionality\n",
    "# Test the search capabilities with various queries\n",
    "\n",
    "if 'store' in globals() and store and store.is_ready():\n",
    "    print(\"üîç Testing Weaviate Search Functionality\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    test_queries = [\n",
    "        \"calculate compound interest rate\",\n",
    "        \"extract text from PDF document\",\n",
    "        \"analyze image data\", \n",
    "        \"solve mathematical equation\",\n",
    "        \"process Excel spreadsheet\",\n",
    "        \"find information online\",\n",
    "        \"convert file format\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\nüîç Query: '{query}'\")\n",
    "        \n",
    "        # Test with direct Weaviate search\n",
    "        results = search_gaia_examples(store.client, query, k=3)\n",
    "        \n",
    "        if results:\n",
    "            for i, (meta, score) in enumerate(results, 1):\n",
    "                print(f\"  {i}. Score: {score:.3f} | Level: {meta.get('level')}\")\n",
    "                print(f\"     Answer: {meta.get('answer', '')[:80]}...\")\n",
    "        else:\n",
    "            print(\"  No results found\")\n",
    "            \n",
    "else:\n",
    "    print(\"‚ùå Store not available. Run Cell 4 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Test LangChain Integration\n",
    "# Test the LangChain wrapper functionality\n",
    "\n",
    "if 'store' in globals() and store and store.is_ready():\n",
    "    print(\"ü¶ú Testing LangChain Integration\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Test LangChain search\n",
    "    test_question = \"How do I calculate compound interest on a monthly basis?\"\n",
    "    \n",
    "    print(f\"Question: {test_question}\")\n",
    "    \n",
    "    # Get relevant examples using LangChain interface\n",
    "    examples = store.get_relevant_examples(test_question, k=3, min_score=0.5)\n",
    "    \n",
    "    print(f\"\\nFound {len(examples)} relevant examples:\")\n",
    "    for i, ex in enumerate(examples, 1):\n",
    "        print(f\"\\n{i}. Similarity: {ex.get('similarity_score', 0):.3f}\")\n",
    "        print(f\"   Level: {ex.get('level')}\")\n",
    "        print(f\"   Q: {ex.get('question', '')[:100]}...\")\n",
    "        print(f\"   A: {ex.get('answer', '')[:100]}...\")\n",
    "    \n",
    "    # Test prompt formatting\n",
    "    formatted_prompt = store.format_for_prompt(examples, max_examples=2)\n",
    "    print(f\"\\nüìã Formatted for prompt:\")\n",
    "    print(formatted_prompt)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Store not available. Run Cell 4 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Test Agent Selection\n",
    "# Test the agent selection based on similar examples\n",
    "\n",
    "if 'store' in globals() and store and store.is_ready():\n",
    "    print(\"ü§ñ Testing Agent Selection\")\n",
    "    print(\"=\" * 35)\n",
    "    \n",
    "    test_scenarios = [\n",
    "        \"Calculate the compound interest for a $10,000 investment\",\n",
    "        \"Extract the main points from this PDF document\", \n",
    "        \"Search for recent news about AI developments\",\n",
    "        \"Analyze the data in this CSV file\",\n",
    "        \"Convert this audio file to text\",\n",
    "        \"What is the capital of France?\"\n",
    "    ]\n",
    "    \n",
    "    for scenario in test_scenarios:\n",
    "        print(f\"\\nüìù Scenario: {scenario}\")\n",
    "        \n",
    "        # Get agent selection with context\n",
    "        agent, context = store.select_agent_with_context(scenario)\n",
    "        \n",
    "        print(f\"üéØ Selected Agent: {agent}\")\n",
    "        print(f\"üìö Context length: {len(context)} characters\")\n",
    "        \n",
    "        # Show first few lines of context\n",
    "        context_preview = '\\n'.join(context.split('\\n')[:3])\n",
    "        print(f\"üìñ Context preview: {context_preview}...\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Store not available. Run Cell 4 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Collection Information and Statistics\n",
    "# Get detailed information about your Weaviate collection\n",
    "\n",
    "if 'store' in globals() and store and store.is_ready():\n",
    "    print(\"üìä Weaviate Collection Analysis\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Get collection info\n",
    "    get_collection_info(store.client)\n",
    "    \n",
    "    # Additional performance testing\n",
    "    print(f\"\\n‚ö° Performance Analysis:\")\n",
    "    \n",
    "    # Test search speed\n",
    "    start_time = time.time()\n",
    "    test_results = search_gaia_examples(store.client, \"test query\", k=5)\n",
    "    search_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"  ‚îú‚îÄ‚îÄ Search time: {search_time:.3f} seconds\")\n",
    "    print(f\"  ‚îú‚îÄ‚îÄ Results returned: {len(test_results)}\")\n",
    "    print(f\"  ‚îî‚îÄ‚îÄ Speed: {len(test_results)/search_time:.1f} results/second\")\n",
    "    \n",
    "    # Memory usage if available\n",
    "    try:\n",
    "        import psutil\n",
    "        memory = psutil.virtual_memory()\n",
    "        print(f\"\\nüíæ Memory Usage: {memory.percent:.1f}%\")\n",
    "        print(f\"  ‚îî‚îÄ‚îÄ Available: {memory.available // 1024 // 1024} MB\")\n",
    "    except ImportError:\n",
    "        print(\"\\nüíæ Install psutil for memory monitoring: poetry add psutil\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Collection analysis complete!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Store not available. Run Cell 4 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Production Integration Functions\n",
    "# Functions ready for your main GAIA agent\n",
    "\n",
    "class GAIAAgentWithWeaviate:\n",
    "    \"\"\"GAIA Agent with Weaviate integration\"\"\"\n",
    "    \n",
    "    def __init__(self, weaviate_store: GAIAWeaviateStore):\n",
    "        self.store = weaviate_store\n",
    "        self.agents = {\n",
    "            \"data_analyst\": \"Handles calculations, data analysis, and mathematical problems\",\n",
    "            \"web_researcher\": \"Searches for information online and retrieves content\", \n",
    "            \"document_processor\": \"Processes files, extracts text, handles attachments\",\n",
    "            \"general_assistant\": \"Handles general questions and reasoning tasks\"\n",
    "        }\n",
    "    \n",
    "    def process_question(self, question: str) -> Dict:\n",
    "        \"\"\"Process a GAIA question with context from similar examples\"\"\"\n",
    "        \n",
    "        # Get agent and context\n",
    "        selected_agent, context = self.store.select_agent_with_context(question)\n",
    "        \n",
    "        # Get relevant examples for additional context\n",
    "        examples = self.store.get_relevant_examples(question, k=2, min_score=0.6)\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"selected_agent\": selected_agent,\n",
    "            \"agent_description\": self.agents.get(selected_agent, \"Unknown agent\"),\n",
    "            \"context\": context,\n",
    "            \"relevant_examples\": len(examples),\n",
    "            \"has_file_examples\": any(ex.get('has_file', False) for ex in examples),\n",
    "            \"example_levels\": [ex.get('level') for ex in examples]\n",
    "        }\n",
    "    \n",
    "    def create_system_prompt(self, question: str) -> str:\n",
    "        \"\"\"Create system prompt with GAIA context\"\"\"\n",
    "        \n",
    "        result = self.process_question(question)\n",
    "        \n",
    "        system_prompt = f\"\"\"You are a general AI assistant working on GAIA benchmark questions.\n",
    "\n",
    "Selected Agent: {result['selected_agent']} - {result['agent_description']}\n",
    "\n",
    "{result['context']}\n",
    "\n",
    "Your task: {question}\n",
    "\n",
    "Report your thoughts, and finish with: FINAL ANSWER: [YOUR FINAL ANSWER].\n",
    "YOUR FINAL ANSWER should be a number OR as few words as possible OR a comma separated list.\n",
    "- Numbers: no commas, no units ($ %) unless specified\n",
    "- Strings: no articles (the, a, an), no abbreviations, digits as text unless specified  \n",
    "- Lists: apply above rules to each element\"\"\"\n",
    "\n",
    "        return system_prompt\n",
    "\n",
    "# Test the production integration\n",
    "if 'store' in globals() and store and store.is_ready():\n",
    "    print(\"üéØ Testing Production Integration\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Create GAIA agent\n",
    "    gaia_agent = GAIAAgentWithWeaviate(store)\n",
    "    \n",
    "    # Test questions\n",
    "    test_questions = [\n",
    "        \"Calculate the compound interest on $5000 at 3% annually for 10 years\",\n",
    "        \"What is the population of Tokyo in 2024?\",\n",
    "        \"Extract the key findings from the attached research paper\"\n",
    "    ]\n",
    "    \n",
    "    for question in test_questions:\n",
    "        print(f\"\\nüìù Question: {question}\")\n",
    "        \n",
    "        # Process question\n",
    "        result = gaia_agent.process_question(question)\n",
    "        print(f\"ü§ñ Agent: {result['selected_agent']}\")\n",
    "        print(f\"üìä Examples found: {result['relevant_examples']}\")\n",
    "        print(f\"üìé Has file examples: {result['has_file_examples']}\")\n",
    "        \n",
    "        # Create system prompt\n",
    "        system_prompt = gaia_agent.create_system_prompt(question)\n",
    "        print(f\"üìÑ System prompt length: {len(system_prompt)} chars\")\n",
    "        \n",
    "        # Show prompt preview\n",
    "        preview = system_prompt.split('\\n')[:3]\n",
    "        print(f\"üìñ Prompt preview: {' '.join(preview)}...\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Store not available. Run Cell 4 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Save and Load Configuration\n",
    "# Save your setup for future use\n",
    "\n",
    "def save_weaviate_config():\n",
    "    \"\"\"Save Weaviate configuration for future sessions\"\"\"\n",
    "    config = {\n",
    "        \"collection_name\": COLLECTION_NAME,\n",
    "        \"embedding_model\": EMBEDDING_MODEL,\n",
    "        \"weaviate_url\": WEAVIATE_URL,\n",
    "        \"setup_complete\": True,\n",
    "        \"total_examples\": len(json_QA) if 'json_QA' in globals() else 0\n",
    "    }\n",
    "    \n",
    "    with open(\"weaviate_gaia_config.json\", \"w\") as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(\"üíæ Configuration saved to: weaviate_gaia_config.json\")\n",
    "    return config\n",
    "\n",
    "def load_weaviate_config():\n",
    "    \"\"\"Load existing Weaviate configuration\"\"\"\n",
    "    try:\n",
    "        with open(\"weaviate_gaia_config.json\", \"r\") as f:\n",
    "            config = json.load(f)\n",
    "        print(\"üìÇ Configuration loaded from: weaviate_gaia_config.json\")\n",
    "        return config\n",
    "    except FileNotFoundError:\n",
    "        print(\"‚ùå No configuration file found\")\n",
    "        return None\n",
    "\n",
    "# Save current configuration\n",
    "if 'store' in globals() and store and store.is_ready():\n",
    "    config = save_weaviate_config()\n",
    "    print(f\"‚úÖ Saved configuration: {config}\")\n",
    "    \n",
    "    # Quick reload test\n",
    "    reloaded_config = load_weaviate_config()\n",
    "    print(f\"üîÑ Reloaded config matches: {config == reloaded_config}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Store not available. Run Cell 4 first.\")\n",
    "\n",
    "print(\"\\nüéâ All notebook cells complete!\")\n",
    "print(\"‚úÖ Your Weaviate GAIA vector store is ready for production use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 11: Quick Restart Function\n",
    "# Use this to quickly restart from a saved state\n",
    "\n",
    "def quick_restart_weaviate():\n",
    "    \"\"\"Quickly restart Weaviate connection from saved state\"\"\"\n",
    "    \n",
    "    # Load config\n",
    "    config = load_weaviate_config()\n",
    "    if not config:\n",
    "        print(\"‚ùå No saved configuration. Run full setup first.\")\n",
    "        return None\n",
    "    \n",
    "    # Check dependencies\n",
    "    if not check_weaviate_dependencies():\n",
    "        return None\n",
    "    \n",
    "    # Connect to Weaviate\n",
    "    client = connect_to_weaviate()\n",
    "    if not client:\n",
    "        print(\"‚ùå Weaviate not running. Start with: docker-compose up -d\")\n",
    "        return None\n",
    "    \n",
    "    # Check if collection exists\n",
    "    if not client.collections.exists(COLLECTION_NAME):\n",
    "        print(\"‚ùå Collection doesn't exist. Run full setup first.\")\n",
    "        return None\n",
    "    \n",
    "    # Create store\n",
    "    store = GAIAWeaviateStore()\n",
    "    \n",
    "    if store.is_ready():\n",
    "        print(\"‚ö° Quick restart successful!\")\n",
    "        get_collection_info(store.client)\n",
    "        return store\n",
    "    else:\n",
    "        print(\"‚ùå Quick restart failed\")\n",
    "        return None\n",
    "\n",
    "# Use this for quick restarts:\n",
    "# store = quick_restart_weaviate()\n",
    "\n",
    "print(\"\\nüöÄ Use quick_restart_weaviate() to quickly reload your setup!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 12: Integration with Your Main GAIA Agent\n",
    "# Final integration code for your main agent\n",
    "\n",
    "\"\"\"\n",
    "# Example integration with your main GAIA agent workflow:\n",
    "\n",
    "def gaia_agent_with_rag(question: str) -> str:\n",
    "    '''Main GAIA agent function with RAG support'''\n",
    "    \n",
    "    # Initialize Weaviate store\n",
    "    store = GAIAWeaviateStore()\n",
    "    \n",
    "    if not store.is_ready():\n",
    "        # Fallback without RAG\n",
    "        return process_without_rag(question)\n",
    "    \n",
    "    # Create agent with RAG\n",
    "    gaia_agent = GAIAAgentWithWeaviate(store)\n",
    "    \n",
    "    # Get system prompt with context\n",
    "    system_prompt = gaia_agent.create_system_prompt(question)\n",
    "    \n",
    "    # Process with your LLM (replace with your actual LLM call)\n",
    "    response = your_llm_call(system_prompt)\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Test the integration\n",
    "test_question = \"Calculate compound interest on $10,000 at 5% for 3 years\"\n",
    "result = gaia_agent_with_rag(test_question)\n",
    "print(f\"Result: {result}\")\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìö Integration example provided above!\")\n",
    "print(\"üéØ Ready to integrate with your main GAIA agent!\")\n",
    "\n",
    "# Final status check\n",
    "if 'store' in globals() and store and store.is_ready():\n",
    "    print(f\"\\n‚úÖ STATUS: Weaviate GAIA store is READY\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ Collection: {COLLECTION_NAME}\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ Embedding model: {EMBEDDING_MODEL}\")\n",
    "    print(f\"   ‚îú‚îÄ‚îÄ NumPy version: {np.__version__}\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ Agent integration: Ready\")\n",
    "else:\n",
    "    print(f\"\\n‚ùå STATUS: Setup incomplete\")\n",
    "    print(f\"   ‚îî‚îÄ‚îÄ Run cells 1-4 to complete setup\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
